{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "1.Language Translation.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yu5dXv0udV_L"
      },
      "source": [
        "Language translation is a method of converting the source sentence from one natural language to another natural language using computerized systems and human assistance is not required."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhGj9ruDdV_d"
      },
      "source": [
        "Deep Learning is a recently used approach for language translation. Unlike traditional machine translation, neural machine translation is a better choice for more accurate translation and also offers better performance. DNN can be used to improve traditional systems to make them more efficient.\n",
        "\n",
        "Different deep learning techniques and libraries are needed to develop a better language translation system. RNN, LSTM, etc. are used to train the system which will convert the sentence from the source language to the target language.\n",
        "\n",
        "Adapting the appropriate networks and deep learning strategies is a good choice, as it has turned the system to maximize the accuracy of the translation system relative to others."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_zuMdRmdV_f"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing\n",
        "\n",
        "import os\n",
        "import string\n",
        "from string import digits\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import re\n",
        "\n",
        "import seaborn as sns\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Input, LSTM, Embedding, Dense\n",
        "from keras.models import Model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yiq2R89dV_j"
      },
      "source": [
        "lines=pd.read_csv(\"Hindi_English_Truncated_Corpus.csv\",encoding='utf-8')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "MFo1AOCqdV_l",
        "outputId": "c1c485c8-6510-48c6-94c1-1b347671bf72"
      },
      "source": [
        "lines.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>english_sentence</th>\n",
              "      <th>hindi_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ted</td>\n",
              "      <td>politicians do not have permission to do what ...</td>\n",
              "      <td>राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ted</td>\n",
              "      <td>I'd like to tell you about one such child,</td>\n",
              "      <td>मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>indic2012</td>\n",
              "      <td>This percentage is even greater than the perce...</td>\n",
              "      <td>यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ted</td>\n",
              "      <td>what we really mean is that they're bad at not...</td>\n",
              "      <td>हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>indic2012</td>\n",
              "      <td>.The ending portion of these Vedas is called U...</td>\n",
              "      <td>इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      source  ...                                     hindi_sentence\n",
              "0        ted  ...  राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...\n",
              "1        ted  ...  मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...\n",
              "2  indic2012  ...   यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।\n",
              "3        ted  ...     हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते\n",
              "4  indic2012  ...        इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlB3wtwjdV_o"
      },
      "source": [
        "lines=lines[lines['source']=='ted']\n",
        "lines=lines[~pd.isnull(lines['english_sentence'])]\n",
        "lines.drop_duplicates(inplace=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiTt8VTPdV_p",
        "outputId": "3a5e196a-42e0-43da-ea8d-70b28750e5bb"
      },
      "source": [
        "# Let us pick any 25000 rows from the dataset\n",
        "lines=lines.sample(n=25000,random_state=42)\n",
        "lines.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZetFoDFdV_q"
      },
      "source": [
        "For simplicity, we will lowercase all the characters in the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxthmaBhdV_s"
      },
      "source": [
        "lines['english_sentence']=lines['english_sentence'].apply(lambda x: x.lower())\n",
        "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.lower())"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vmlBZJJdV_t"
      },
      "source": [
        "Now we will remove all the special characters in the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH0kOND8dV_u"
      },
      "source": [
        "remove_digits = str.maketrans('', '', digits)\n",
        "lines['english_sentence']=lines['english_sentence'].apply(lambda x: x.translate(remove_digits))\n",
        "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.translate(remove_digits))\n",
        "\n",
        "lines['hindi_sentence'] = lines['hindi_sentence'].apply(lambda x: re.sub(\"[२३०८१५७९४६]\", \"\", x))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWijDjBIdV_v"
      },
      "source": [
        "# Remove extra spaces\n",
        "lines['english_sentence']=lines['english_sentence'].apply(lambda x: x.strip())\n",
        "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.strip())\n",
        "lines['english_sentence']=lines['english_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\n",
        "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBE0ZErZdV_w"
      },
      "source": [
        "lines['hindi_sentence'] = lines['hindi_sentence'].apply(lambda x : 'START_ '+ x + ' _END')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTfCL5Y6dV_x"
      },
      "source": [
        "Now we have cleared the dataset the next thing we need to do is to prepare two sets of vocabularies of Hindi and English:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMBgbLhldV_y"
      },
      "source": [
        "# Get English and Hindi Vocabulary\n",
        "all_eng_words=set()\n",
        "for eng in lines['english_sentence']:\n",
        "    for word in eng.split():\n",
        "        if word not in all_eng_words:\n",
        "            all_eng_words.add(word)\n",
        "\n",
        "all_hindi_words=set()\n",
        "for hin in lines['hindi_sentence']:\n",
        "    for word in hin.split():\n",
        "        if word not in all_hindi_words:\n",
        "            all_hindi_words.add(word)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sa-2Ax-WdV_y"
      },
      "source": [
        "lines['length_eng_sentence']=lines['english_sentence'].apply(lambda x:len(x.split(\" \")))\n",
        "lines['length_hin_sentence']=lines['hindi_sentence'].apply(lambda x:len(x.split(\" \")))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOdE94iudV_z"
      },
      "source": [
        "Before training the language translation model we need to set the input and target values:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXZ43Y_wdV_0"
      },
      "source": [
        "lines=lines[lines['length_eng_sentence']<=20]\n",
        "lines=lines[lines['length_hin_sentence']<=20]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7dJYs8CdV_1"
      },
      "source": [
        "max_length_src=max(lines['length_hin_sentence'])\n",
        "max_length_tar=max(lines['length_eng_sentence'])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NmZmMiFdV_2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e4e09e4-e5f7-4443-e7bf-34bb0b0719e3"
      },
      "source": [
        "input_words = sorted(list(all_eng_words))\n",
        "target_words = sorted(list(all_hindi_words))\n",
        "num_encoder_tokens = len(all_eng_words)+1\n",
        "num_decoder_tokens = len(all_hindi_words)+1\n",
        "num_encoder_tokens, num_decoder_tokens"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21137, 20742)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-gTS1U7dV_3"
      },
      "source": [
        "num_decoder_tokens += 1 #for zero padding\n",
        "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
        "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])\n",
        "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())\n",
        "lines = shuffle(lines)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2upbK5OldV_4"
      },
      "source": [
        "### Training Model to Translate English to Hindi\n",
        "\n",
        "As we have prepared our dataset let’s train a model for Language translation. For this we will first split the data and then we will move forward to train our model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nq1wDuzdV_6"
      },
      "source": [
        "X, y = lines['english_sentence'], lines['hindi_sentence']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=42)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYlfQsgldV_7"
      },
      "source": [
        "X_train.to_pickle('X_train.pkl')\n",
        "X_test.to_pickle('X_test.pkl')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAKo3qRndV_8"
      },
      "source": [
        "Now let’s train our language translation model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcycYVmVdV_8"
      },
      "source": [
        "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
        "    ''' Generate a batch of data '''\n",
        "    while True:\n",
        "        for j in range(0, len(X), batch_size):\n",
        "            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n",
        "            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n",
        "            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n",
        "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
        "                for t, word in enumerate(input_text.split()):\n",
        "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
        "                for t, word in enumerate(target_text.split()):\n",
        "                    if t<len(target_text.split())-1:\n",
        "                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n",
        "                    if t>0:\n",
        "                        # decoder target sequence (one hot encoded)\n",
        "                        # does not include the START_ token\n",
        "                        # Offset by one timestep\n",
        "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
        "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Va2N2gj1dV_9"
      },
      "source": [
        "latent_dim=300\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "enc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\n",
        "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPXxmBhudV_-"
      },
      "source": [
        "# We discard `encoder_outputs` and only keep the states.\n",
        "encoder_states = [state_h, state_c]\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGrftTIEdV_-"
      },
      "source": [
        "# We set up our decoder to return full output sequences,\n",
        "# and to return internal states as well. We don't use the\n",
        "# return states in the training model, but we will use them in inference.\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_emb,initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxtSoqYsdV__",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c741cc7-0a45-482e-9bd3-1481ef42087c"
      },
      "source": [
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
        "model.summary()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, None, 300)    6341100     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 300)    6222900     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 300), (None, 721200      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, None, 300),  721200      embedding_1[0][0]                \n",
            "                                                                 lstm[0][1]                       \n",
            "                                                                 lstm[0][2]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 20743)  6243643     lstm_1[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 20,250,043\n",
            "Trainable params: 20,250,043\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNSyb34-dWAA"
      },
      "source": [
        "train_samples = len(X_train)\n",
        "val_samples = len(X_test)\n",
        "batch_size = 128\n",
        "epochs = 100"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vF-WhiSkdWAA",
        "outputId": "5bef04b4-1976-49b6-bea0-83f7113e45c6"
      },
      "source": [
        "model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n",
        "                    steps_per_epoch = train_samples//batch_size,epochs=epochs,\n",
        "                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n",
        "                    validation_steps = val_samples//batch_size)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "154/154 [==============================] - 49s 230ms/step - loss: 3.1555 - val_loss: 3.0323\n",
            "Epoch 2/100\n",
            "154/154 [==============================] - 33s 213ms/step - loss: 2.8783 - val_loss: 2.8685\n",
            "Epoch 3/100\n",
            "154/154 [==============================] - 33s 212ms/step - loss: 2.7036 - val_loss: 2.7882\n",
            "Epoch 4/100\n",
            "154/154 [==============================] - 33s 212ms/step - loss: 2.5837 - val_loss: 2.7307\n",
            "Epoch 5/100\n",
            "154/154 [==============================] - 33s 218ms/step - loss: 2.4885 - val_loss: 2.7046\n",
            "Epoch 6/100\n",
            "154/154 [==============================] - 33s 217ms/step - loss: 2.4062 - val_loss: 2.6689\n",
            "Epoch 7/100\n",
            "154/154 [==============================] - 32s 210ms/step - loss: 2.3264 - val_loss: 2.6587\n",
            "Epoch 8/100\n",
            "154/154 [==============================] - 33s 214ms/step - loss: 2.2497 - val_loss: 2.6384\n",
            "Epoch 9/100\n",
            "154/154 [==============================] - 33s 214ms/step - loss: 2.1780 - val_loss: 2.6252\n",
            "Epoch 10/100\n",
            "154/154 [==============================] - 34s 224ms/step - loss: 2.1071 - val_loss: 2.6295\n",
            "Epoch 11/100\n",
            "154/154 [==============================] - 35s 225ms/step - loss: 2.0386 - val_loss: 2.6210\n",
            "Epoch 12/100\n",
            "154/154 [==============================] - 35s 225ms/step - loss: 1.9721 - val_loss: 2.6250\n",
            "Epoch 13/100\n",
            "154/154 [==============================] - 34s 224ms/step - loss: 1.9082 - val_loss: 2.6440\n",
            "Epoch 14/100\n",
            "154/154 [==============================] - 34s 224ms/step - loss: 1.8443 - val_loss: 2.6459\n",
            "Epoch 15/100\n",
            "154/154 [==============================] - 35s 224ms/step - loss: 1.7843 - val_loss: 2.6572\n",
            "Epoch 16/100\n",
            "154/154 [==============================] - 35s 226ms/step - loss: 1.7234 - val_loss: 2.6738\n",
            "Epoch 17/100\n",
            "154/154 [==============================] - 34s 223ms/step - loss: 1.6644 - val_loss: 2.6942\n",
            "Epoch 18/100\n",
            "154/154 [==============================] - 34s 223ms/step - loss: 1.6070 - val_loss: 2.7046\n",
            "Epoch 19/100\n",
            "154/154 [==============================] - 34s 223ms/step - loss: 1.5502 - val_loss: 2.7332\n",
            "Epoch 20/100\n",
            "154/154 [==============================] - 35s 224ms/step - loss: 1.4932 - val_loss: 2.7580\n",
            "Epoch 21/100\n",
            "154/154 [==============================] - 35s 228ms/step - loss: 1.4394 - val_loss: 2.7703\n",
            "Epoch 22/100\n",
            "154/154 [==============================] - 35s 225ms/step - loss: 1.3855 - val_loss: 2.8000\n",
            "Epoch 23/100\n",
            "154/154 [==============================] - 35s 225ms/step - loss: 1.3332 - val_loss: 2.8190\n",
            "Epoch 24/100\n",
            "154/154 [==============================] - 35s 225ms/step - loss: 1.2828 - val_loss: 2.8469\n",
            "Epoch 25/100\n",
            "154/154 [==============================] - 34s 224ms/step - loss: 1.2325 - val_loss: 2.8743\n",
            "Epoch 26/100\n",
            "154/154 [==============================] - 35s 225ms/step - loss: 1.1843 - val_loss: 2.8988\n",
            "Epoch 27/100\n",
            "154/154 [==============================] - 35s 225ms/step - loss: 1.1376 - val_loss: 2.9297\n",
            "Epoch 28/100\n",
            "154/154 [==============================] - 35s 226ms/step - loss: 1.0899 - val_loss: 2.9517\n",
            "Epoch 29/100\n",
            "154/154 [==============================] - 35s 225ms/step - loss: 1.0437 - val_loss: 2.9793\n",
            "Epoch 30/100\n",
            "154/154 [==============================] - 34s 224ms/step - loss: 0.9994 - val_loss: 3.0128\n",
            "Epoch 31/100\n",
            "154/154 [==============================] - 35s 226ms/step - loss: 0.9555 - val_loss: 3.0409\n",
            "Epoch 32/100\n",
            "154/154 [==============================] - 35s 225ms/step - loss: 0.9151 - val_loss: 3.0552\n",
            "Epoch 33/100\n",
            "154/154 [==============================] - 35s 224ms/step - loss: 0.8758 - val_loss: 3.0827\n",
            "Epoch 34/100\n",
            "154/154 [==============================] - 35s 225ms/step - loss: 0.8379 - val_loss: 3.1118\n",
            "Epoch 35/100\n",
            "154/154 [==============================] - 35s 225ms/step - loss: 0.8017 - val_loss: 3.1331\n",
            "Epoch 36/100\n",
            "154/154 [==============================] - 35s 225ms/step - loss: 0.7687 - val_loss: 3.1626\n",
            "Epoch 37/100\n",
            "154/154 [==============================] - 35s 225ms/step - loss: 0.7342 - val_loss: 3.1798\n",
            "Epoch 38/100\n",
            "154/154 [==============================] - 35s 224ms/step - loss: 0.7019 - val_loss: 3.2220\n",
            "Epoch 39/100\n",
            "154/154 [==============================] - 35s 225ms/step - loss: 0.6717 - val_loss: 3.2386\n",
            "Epoch 40/100\n",
            "154/154 [==============================] - 35s 225ms/step - loss: 0.6415 - val_loss: 3.2694\n",
            "Epoch 41/100\n",
            "154/154 [==============================] - 35s 225ms/step - loss: 0.6145 - val_loss: 3.2872\n",
            "Epoch 42/100\n",
            "154/154 [==============================] - 35s 225ms/step - loss: 0.5864 - val_loss: 3.2988\n",
            "Epoch 43/100\n",
            "154/154 [==============================] - 34s 223ms/step - loss: 0.5607 - val_loss: 3.3200\n",
            "Epoch 44/100\n",
            "154/154 [==============================] - 35s 226ms/step - loss: 0.5365 - val_loss: 3.3356\n",
            "Epoch 45/100\n",
            "154/154 [==============================] - 35s 225ms/step - loss: 0.5133 - val_loss: 3.3547\n",
            "Epoch 46/100\n",
            "154/154 [==============================] - 35s 226ms/step - loss: 0.4907 - val_loss: 3.3760\n",
            "Epoch 47/100\n",
            "154/154 [==============================] - 35s 227ms/step - loss: 0.4698 - val_loss: 3.3972\n",
            "Epoch 48/100\n",
            "154/154 [==============================] - 35s 225ms/step - loss: 0.4501 - val_loss: 3.4188\n",
            "Epoch 49/100\n",
            "154/154 [==============================] - 35s 226ms/step - loss: 0.4307 - val_loss: 3.4396\n",
            "Epoch 50/100\n",
            "154/154 [==============================] - 35s 225ms/step - loss: 0.4127 - val_loss: 3.4463\n",
            "Epoch 51/100\n",
            "154/154 [==============================] - 35s 225ms/step - loss: 0.3955 - val_loss: 3.4730\n",
            "Epoch 52/100\n",
            "154/154 [==============================] - 35s 226ms/step - loss: 0.3789 - val_loss: 3.4863\n",
            "Epoch 53/100\n",
            "154/154 [==============================] - 35s 226ms/step - loss: 0.3632 - val_loss: 3.5059\n",
            "Epoch 54/100\n",
            "154/154 [==============================] - 34s 224ms/step - loss: 0.3490 - val_loss: 3.5187\n",
            "Epoch 55/100\n",
            "154/154 [==============================] - 35s 225ms/step - loss: 0.3354 - val_loss: 3.5428\n",
            "Epoch 56/100\n",
            "154/154 [==============================] - 35s 226ms/step - loss: 0.3224 - val_loss: 3.5515\n",
            "Epoch 57/100\n",
            "154/154 [==============================] - 35s 225ms/step - loss: 0.3107 - val_loss: 3.5672\n",
            "Epoch 58/100\n",
            "154/154 [==============================] - 35s 226ms/step - loss: 0.2983 - val_loss: 3.5791\n",
            "Epoch 59/100\n",
            "154/154 [==============================] - 35s 225ms/step - loss: 0.2868 - val_loss: 3.5899\n",
            "Epoch 60/100\n",
            "154/154 [==============================] - 35s 226ms/step - loss: 0.2764 - val_loss: 3.6084\n",
            "Epoch 61/100\n",
            "154/154 [==============================] - 35s 226ms/step - loss: 0.2662 - val_loss: 3.6155\n",
            "Epoch 62/100\n",
            "154/154 [==============================] - 35s 226ms/step - loss: 0.2567 - val_loss: 3.6265\n",
            "Epoch 63/100\n",
            "154/154 [==============================] - 35s 227ms/step - loss: 0.2469 - val_loss: 3.6393\n",
            "Epoch 64/100\n",
            "154/154 [==============================] - 35s 226ms/step - loss: 0.2389 - val_loss: 3.6375\n",
            "Epoch 65/100\n",
            "154/154 [==============================] - 35s 225ms/step - loss: 0.2294 - val_loss: 3.6612\n",
            "Epoch 66/100\n",
            "154/154 [==============================] - 35s 226ms/step - loss: 0.2222 - val_loss: 3.6656\n",
            "Epoch 67/100\n",
            "154/154 [==============================] - 35s 227ms/step - loss: 0.2145 - val_loss: 3.6768\n",
            "Epoch 68/100\n",
            "154/154 [==============================] - 35s 226ms/step - loss: 0.2077 - val_loss: 3.6785\n",
            "Epoch 69/100\n",
            "154/154 [==============================] - 35s 228ms/step - loss: 0.2003 - val_loss: 3.6941\n",
            "Epoch 70/100\n",
            "154/154 [==============================] - 35s 226ms/step - loss: 0.1945 - val_loss: 3.7133\n",
            "Epoch 71/100\n",
            "154/154 [==============================] - 35s 226ms/step - loss: 0.1892 - val_loss: 3.7140\n",
            "Epoch 72/100\n",
            "154/154 [==============================] - 35s 225ms/step - loss: 0.1825 - val_loss: 3.7268\n",
            "Epoch 73/100\n",
            "154/154 [==============================] - 35s 227ms/step - loss: 0.1770 - val_loss: 3.7350\n",
            "Epoch 74/100\n",
            "154/154 [==============================] - 35s 226ms/step - loss: 0.1722 - val_loss: 3.7421\n",
            "Epoch 75/100\n",
            "154/154 [==============================] - 35s 226ms/step - loss: 0.1676 - val_loss: 3.7492\n",
            "Epoch 76/100\n",
            "154/154 [==============================] - 35s 226ms/step - loss: 0.1627 - val_loss: 3.7604\n",
            "Epoch 77/100\n",
            "154/154 [==============================] - 35s 226ms/step - loss: 0.1578 - val_loss: 3.7624\n",
            "Epoch 78/100\n",
            "154/154 [==============================] - 35s 226ms/step - loss: 0.1533 - val_loss: 3.7800\n",
            "Epoch 79/100\n",
            "154/154 [==============================] - 35s 227ms/step - loss: 0.1494 - val_loss: 3.7855\n",
            "Epoch 80/100\n",
            "154/154 [==============================] - 35s 227ms/step - loss: 0.1467 - val_loss: 3.7953\n",
            "Epoch 81/100\n",
            "154/154 [==============================] - 35s 225ms/step - loss: 0.1429 - val_loss: 3.7946\n",
            "Epoch 82/100\n",
            "154/154 [==============================] - 35s 227ms/step - loss: 0.1399 - val_loss: 3.8071\n",
            "Epoch 83/100\n",
            "154/154 [==============================] - 35s 226ms/step - loss: 0.1359 - val_loss: 3.8158\n",
            "Epoch 84/100\n",
            "154/154 [==============================] - 35s 227ms/step - loss: 0.1335 - val_loss: 3.8181\n",
            "Epoch 85/100\n",
            "154/154 [==============================] - 35s 227ms/step - loss: 0.1308 - val_loss: 3.8327\n",
            "Epoch 86/100\n",
            "154/154 [==============================] - 35s 226ms/step - loss: 0.1281 - val_loss: 3.8371\n",
            "Epoch 87/100\n",
            "154/154 [==============================] - 35s 228ms/step - loss: 0.1254 - val_loss: 3.8469\n",
            "Epoch 88/100\n",
            "154/154 [==============================] - 35s 227ms/step - loss: 0.1225 - val_loss: 3.8445\n",
            "Epoch 89/100\n",
            "154/154 [==============================] - 35s 228ms/step - loss: 0.1199 - val_loss: 3.8499\n",
            "Epoch 90/100\n",
            "154/154 [==============================] - 35s 227ms/step - loss: 0.1166 - val_loss: 3.8541\n",
            "Epoch 91/100\n",
            "154/154 [==============================] - 35s 228ms/step - loss: 0.1143 - val_loss: 3.8599\n",
            "Epoch 92/100\n",
            "154/154 [==============================] - 35s 227ms/step - loss: 0.1120 - val_loss: 3.8589\n",
            "Epoch 93/100\n",
            "154/154 [==============================] - 35s 225ms/step - loss: 0.1108 - val_loss: 3.8680\n",
            "Epoch 94/100\n",
            "154/154 [==============================] - 35s 224ms/step - loss: 0.1084 - val_loss: 3.8781\n",
            "Epoch 95/100\n",
            "154/154 [==============================] - 34s 224ms/step - loss: 0.1059 - val_loss: 3.8852\n",
            "Epoch 96/100\n",
            "154/154 [==============================] - 35s 227ms/step - loss: 0.1039 - val_loss: 3.8885\n",
            "Epoch 97/100\n",
            "154/154 [==============================] - 35s 225ms/step - loss: 0.1013 - val_loss: 3.8853\n",
            "Epoch 98/100\n",
            "154/154 [==============================] - 35s 225ms/step - loss: 0.0997 - val_loss: 3.8891\n",
            "Epoch 99/100\n",
            "154/154 [==============================] - 34s 223ms/step - loss: 0.0980 - val_loss: 3.8983\n",
            "Epoch 100/100\n",
            "154/154 [==============================] - 35s 225ms/step - loss: 0.0954 - val_loss: 3.9060\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faa903f35d0>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFZYZgemdWAB"
      },
      "source": [
        "model.save_weights('nmt_weights.h5')"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiBo0xx9dWAC"
      },
      "source": [
        "# Encode the input sequence to get the \"thought vectors\"\n",
        "encoder_model = Model(encoder_inputs, encoder_states)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6v1Rz3FqdWAC"
      },
      "source": [
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGKAKrR7dWAD"
      },
      "source": [
        "dec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kS2K1g5GdWAE"
      },
      "source": [
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
        "decoder_states2 = [state_h2, state_c2]\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPjVJKaddWAF"
      },
      "source": [
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs2] + decoder_states2)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esas5RzidWAF"
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0] = target_token_index['START_']\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += ' '+sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if (sampled_char == '_END' or\n",
        "           len(decoded_sentence) > 50):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHurFpLqdWAG"
      },
      "source": [
        "train_gen = generate_batch(X_train, y_train, batch_size = 1)\n",
        "k=-1"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2z1orcsOJy09"
      },
      "source": [
        ""
      ],
      "execution_count": 37,
      "outputs": []
    }
  ]
}