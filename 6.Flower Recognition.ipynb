{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flower recognition uses the edge and colour characteristics of flower images to classify flowers. There are many species of flowers in the world. Some species have many colours, such as roses. It is difficult to remember all the names of flowers and their information. Additionally, someone may be confused with similar flower species.\n",
    "\n",
    "For example, white champaka and champak have similar names and petal shapes, but they have different colours and petal lengths.\n",
    "\n",
    "At present, it is almost impossible to identify any particular flower or flower species in any way other than to seek information based on personal knowledge and expert experience. The availability of such experts can be an obstacle to this search for information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Searching for such information on the Internet today is very limited to keyword research; word processor. Even then, the searcher has to come up with sufficiently useful keywords, which they cannot do, which is the crux of the matter.\n",
    "\n",
    "The dataset we are using here for the flower recognition contains 4242 flower images. Data collection is based on Flickr data, google images, Yandex images. We can use this data set to recognize the flowers in the photo.\n",
    "\n",
    "The images are divided into five classes: chamomile, tulip, rose, sunflower, dandelion. For each class, there are approximately 800 photos. The photos are not in high resolution, approximately `320×240` pixels. Photos are not reduced to one size, they have different proportions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#Encoding and Split data into Train/Test Sets\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Tensorflow Keras CNN Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n",
    "\n",
    "#Plot Images\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_dir = 'flowers'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the next step is to read each image in the data and create a label for each with the name of the folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "label = []\n",
    "\n",
    "SIZE = 128 #Crop the image to 128x128\n",
    "\n",
    "for folder in os.listdir(folder_dir):\n",
    "    for file in os.listdir(os.path.join(folder_dir, folder)):\n",
    "        if file.endswith(\"jpg\"):\n",
    "            label.append(folder)\n",
    "            img = cv2.imread(os.path.join(folder_dir, folder, file))\n",
    "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            im = cv2.resize(img_rgb, (SIZE,SIZE))\n",
    "            data.append(im)\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s convert the data into numerical values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_arr = np.array(data)\n",
    "label_arr = np.array(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s use the Label encoder and normalize the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(label_arr)\n",
    "y = to_categorical(y,5)\n",
    "X = data_arr/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to split the dataset into 80% training and 20% test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s build a neural network model for Flower Recognition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same',activation ='relu', input_shape = (SIZE,SIZE,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n",
    "model.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n",
    "model.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(5, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before compiling the model we need to create more training images to prevent overfitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        zoom_range = 0.20,\n",
    "        width_shift_range=0.3,\n",
    "        height_shift_range=0.3,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s compile the neural network model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=0.0001),loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "108/108 [==============================] - 1000s 8s/step - loss: 1.5616 - accuracy: 0.2796 - val_loss: 1.2831 - val_accuracy: 0.4803\n",
      "Epoch 2/64\n",
      "108/108 [==============================] - 1127s 10s/step - loss: 1.3204 - accuracy: 0.4317 - val_loss: 1.1818 - val_accuracy: 0.4907\n",
      "Epoch 3/64\n",
      "108/108 [==============================] - 1022s 9s/step - loss: 1.2606 - accuracy: 0.4630 - val_loss: 1.1751 - val_accuracy: 0.5185\n",
      "Epoch 4/64\n",
      "108/108 [==============================] - 973s 9s/step - loss: 1.2140 - accuracy: 0.5136 - val_loss: 1.0947 - val_accuracy: 0.5648\n",
      "Epoch 5/64\n",
      "108/108 [==============================] - 1012s 9s/step - loss: 1.1915 - accuracy: 0.5133 - val_loss: 1.0496 - val_accuracy: 0.5764\n",
      "Epoch 6/64\n",
      "108/108 [==============================] - 961s 9s/step - loss: 1.1552 - accuracy: 0.5382 - val_loss: 0.9631 - val_accuracy: 0.6319\n",
      "Epoch 7/64\n",
      "108/108 [==============================] - 942s 9s/step - loss: 1.0824 - accuracy: 0.5626 - val_loss: 0.9928 - val_accuracy: 0.5833\n",
      "Epoch 8/64\n",
      "108/108 [==============================] - 987s 9s/step - loss: 1.0713 - accuracy: 0.5685 - val_loss: 0.9937 - val_accuracy: 0.5961\n",
      "Epoch 9/64\n",
      "108/108 [==============================] - 1073s 10s/step - loss: 1.0124 - accuracy: 0.6126 - val_loss: 0.9435 - val_accuracy: 0.6204\n",
      "Epoch 10/64\n",
      "107/108 [============================>.] - ETA: 8s - loss: 1.0194 - accuracy: 0.6035 "
     ]
    }
   ],
   "source": [
    "batch_size=32\n",
    "epochs=64\n",
    "history = model.fit_generator(datagen.flow(X_train,y_train, batch_size=batch_size),\n",
    "                              epochs = epochs,\n",
    "                              validation_data = (X_test,y_test),\n",
    "                              verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s let the model if it recognize flowers properly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = np.sort(os.listdir(folder_dir))\n",
    "fig, ax = plt.subplots(6,6, figsize=(25, 40))\n",
    "\n",
    "for i in range(6):\n",
    "    for j in range(6):\n",
    "        k = int(np.random.random_sample() * len(X_test))\n",
    "        if(categories[np.argmax(y_test[k])] == categories[np.argmax(model.predict(X_test)[k])]):\n",
    "            ax[i,j].set_title(\"TRUE: \" + categories[np.argmax(y_test[k])], color='green')\n",
    "            ax[i,j].set_xlabel(\"PREDICTED: \" + categories[np.argmax(model.predict(X_test)[k])], color='green')\n",
    "            ax[i,j].imshow(np.array(X_test)[k].reshape(SIZE, SIZE, 3), cmap='gray')\n",
    "        else:\n",
    "            ax[i,j].set_title(\"TRUE: \" + categories[np.argmax(y_test[k])], color='red')\n",
    "            ax[i,j].set_xlabel(\"PREDICTED: \" + categories[np.argmax(model.predict(X_test)[k])], color='red')\n",
    "            ax[i,j].imshow(np.array(X_test)[k].reshape(SIZE, SIZE, 3), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
